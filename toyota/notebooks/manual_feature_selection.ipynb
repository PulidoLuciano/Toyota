{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitacora de Manual Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook explicamos como hemos hecho la seleccion de variables. No hay ejecuciones, vamos a mencionar unicamente porque fuimos eliminando cada variable.\n",
    "\n",
    "Para comenzar hablamos del baseline, donde se ejecuto el modelo por defecto eliminando las variables de cadenas. Se contaba con 34 variables iniciales y se obtuvo un r2 de 0.8730 con un rmse de 1272.\n",
    "\n",
    "Luego de agregar las variables obtenidas el promedio de r2 se fue a 0.9028 con un promedio RMSE de 1066.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = ln_transform.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar el summary y la matriz de correlacion para ir descartando variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(df, annotated=True):\n",
    "    corr_matrix = df.corr(method='pearson')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=annotated, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.title('Matriz de CorrelaciÃ³n')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(df, annotated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a empezar eliminando Central Lock que tiene alta colinealidad con Powered Windows y en los summary tiene t-values muy bajos con alto P>|t|. El modelo no sufre casi nada.\n",
    "\n",
    "La siguiente es Met_Color que en los summary tiene t-values muy bajos con alto P>|t|. Ademas de poca correlacion con precio. El modelo mejora con este drop.\n",
    "\n",
    "Con el mismo criterio se elimina los features: \"Central_Lock\", \"Met_Color\", \"Airbag_2\", \"ABS\", \"Backseat_Divider\", \"Metallic_Rim\", \"Radio\", \"Diesel\", \"Airbag_1\", \"Sport_Model\", \"m_vvti\", \"m_16v\".\n",
    "\n",
    "Automatic tenia malos valores pero lo estabamos haciendo aguantar porque creaiamos que podia influir, luego de borrar todas las anteriores los t-values siguen siendo cercanos a -0.9 con P>|t| de 0.3. Decidimos sacarla finalmente porque tampoco tiene buena correlacion de person.\n",
    "\n",
    "El modelo tiene en la validacion cruzada con k-fold un promedio de:\n",
    "- r2 = 0.9065\n",
    "- rmse = 1052\n",
    "- mae = 785\n",
    "\n",
    "Vamos a hacer de nuevo otra matriz sin las columnas ya eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Central_Lock\", \"Met_Color\", \"Airbag_2\", \"ABS\", \"Backseat_Divider\", \"Metallic_Rim\", \"Radio\", \"Diesel\", \"Airbag_1\", \"Sport_Model\", \"m_vvti\", \"m_16v\", \"Automatic\"], inplace=True)\n",
    "corr_matrix(df, annotated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Gears\", \"m_sedan\", \"m_bns\", \"m_wagon\" son otras features obvias de sacar segun el summary y la correlacion.\n",
    "\n",
    "\"Power_Steering\" y \"Mistlamps\" parecen empezar a ser las ultimas obvias, con t-values de entre -1.5 y -2.5, y con P>|t| de 0.1 aproximadamente. Al sacarlas el modelo empeora 0.01 en r2 y 1 punto en RMSE, pero mejora en BIC con todos los folds. Mantenemos la decision de sacar las variables.\n",
    "\n",
    "Sacando las variables anteriores \"Tow_Bar\" empeora sus t-values. La situacion es similar a las variables anteriores, mejora BIC pero empeora demasiado poco en los otros valores para ser relevante.\n",
    "\n",
    "Doors se comporta de manera extrania. En dos folds tiene buenos valores decentes de P>|t| y en otros dos supera los 0,2. Los coeficientes sin embargo son generalmente bajos, y teniendo en cuenta que no hay mucha relacion con precio la sacamos. El modelo mejora los BIC en los folds y solo empeora 0,0002 en r2 promedio, mantenemos el cambio.\n",
    "\n",
    "Misma situacion con m_matic4 y m_matic3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Gears\", \"m_sedan\", \"m_bns\", \"m_wagon\", \"Power_Steering\", \"Mistlamps\", \"Tow_Bar\", \"Five_Doors\", \"Trunk\", \"m_exec\", \"m_matic4\", \"m_matic3\"], inplace=True)\n",
    "corr_matrix(df, annotated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto todas las variables ya estan con t-values mayores a 2 y P>|t| menores a 0,05. Empezaremos a darle mas importancia a la correlacion con el precio a la hora de borrar features, aunque no dejaremos de tener en cuenta estos valores. \n",
    "\n",
    "\"m_g6\", \"m_gtsi\" y \"m_sport\" tienen correlaciones muy bajas y sus t-values cercanos a 2. Sus coeficientes tambien son bajos respecto al resto. Eliminamos.\n",
    "\n",
    "\"cc\" no tiene mucha relacion con precio y tiene cierta colinealidad con weight. Empeora bastante mas de lo esperado, volvemos atras.\n",
    "\n",
    "Probamos sacando BoardComputer, que esta muy relacionada con CD_Player y Mfg_Year. No empeora casi nada, seguimos con este.\n",
    "\n",
    "Al ir eliminando variables los t-values de m_sol, m_luna y m_terra empeoraron bastante. Son eliminados en orden inverso al mencionado. Luego, lo mismo sucede con \"m_comfort\", aunque con esta ultima solo mejora el BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"m_g6\", \"m_gtsi\", \"m_sport\", \"Boardcomputer\", \"m_sol\", \"m_luna\", \"m_terra\", \"m_comfort\"], inplace=True)\n",
    "corr_matrix(df, annotated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airco tiene alta correlacion con precio pero su coeficiente es muy bajo. Ademas su relacion con peso y anio puede estar influenciando. Eliminamos y el modelo empeora levemente. Vamos a probar otra variable.\n",
    "\n",
    "\"BOVAG_Guarantee\" tiene muy poca relacion con precio y coeficientes relativamente bajos con respecto al resto. Igual que el anterior.\n",
    "\n",
    "Probamos \"Powered_Windows\". Peor que los anteriores.\n",
    "\n",
    "Parecemos haber llegado a un punto de inflexion donde quitar variables empeora sistematicamente el modelo en todos sus valores.\n",
    "\n",
    "Vamos a eliminar las columnas de igual modo. Porque no empeora demasiado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacando \"Mfr_Guarantee\" el modelo mejora un poco hacia el final. Por lo que lo sacamos.\n",
    "\n",
    "Seguimos probando con \"m_batch_b\" y \"m_liftb\" que tienen coeficientes bajos en comparacion al resto.\n",
    "\n",
    "Lo mismo con \"m_d4d\".\n",
    "\n",
    "A partir de aqui el modelo solo empeora, consideramos que no tiene sentido seguir eliminando variables. En la carpeta de notebooks del proyecto hay dos imagenes con los valores promedios de validacion cruzada (r2, mse, rmse y mae) para cada ejecucion en mlflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toyota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
