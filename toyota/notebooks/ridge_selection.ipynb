{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "toyota = cut_outliers.copy()\n",
    "\n",
    "def ridge_selection(X_train, X_test, y_train, y_test, min_alpha=0, max_alpha=4, steps=100, n_worst=5):\n",
    "    clf = Ridge()\n",
    "\n",
    "    # Generate values for `alpha` that are evenly distributed on a logarithmic scale\n",
    "    alphas = np.logspace(min_alpha, max_alpha, steps)\n",
    "    coefs = []\n",
    "    rmse_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    # Train the model with different regularisation strengths\n",
    "    for a in alphas:\n",
    "        clf.set_params(alpha=a).fit(X_train, y_train)\n",
    "        coefs.append(clf.coef_)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse_list.append(np.sqrt(mse))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    alphas = pd.Index(alphas, name=\"alpha\")\n",
    "    coefs = pd.DataFrame(coefs, index=alphas, columns=[f\"{name}\" for _, name in enumerate(X_train.columns)])\n",
    "    coefs_plot(coefs)\n",
    "    rmse_plot(alphas, rmse_list)\n",
    "    r2_plot(alphas, r2_list)\n",
    "    worst_coefs = print_coefs(coefs, rmse_list).tail(n_worst).index.tolist()\n",
    "    return worst_coefs\n",
    "\n",
    "def coefs_plot(coefs):\n",
    "    sns.lineplot(data=coefs)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "def rmse_plot(alphas, rmse_list):\n",
    "    sns.lineplot(x=alphas, y=rmse_list)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    # Find and mark the minimum MSE point\n",
    "    min_mse_idx = np.argmin(rmse_list)\n",
    "    min_alpha = alphas[min_mse_idx]\n",
    "    min_mse = rmse_list[min_mse_idx]\n",
    "    plt.plot(min_alpha, min_mse, 'ro', label=f'Min RMSE: {min_mse:.2f}\\nAlpha: {min_alpha:.2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def r2_plot(alphas, r2_list):\n",
    "    sns.lineplot(x=alphas, y=r2_list)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylabel(\"R2\")\n",
    "    min_r2_idx = np.argmax(r2_list)\n",
    "    min_alpha = alphas[min_r2_idx]\n",
    "    min_r2 = r2_list[min_r2_idx]\n",
    "    plt.plot(min_alpha, min_r2, 'ro', label=f'Min R2: {min_r2:.2f}\\nAlpha: {min_alpha:.2e}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def print_coefs(coefs, mse_list):\n",
    "    min_mse_idx = np.argmin(mse_list)\n",
    "    coefs_df = np.abs(coefs.iloc[min_mse_idx]).sort_values(ascending=False)\n",
    "    print(coefs_df)\n",
    "    return coefs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer la primera ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = toyota.drop(columns=[\"Price\"], axis=1)\n",
    "y = toyota[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "ridge_selection(X_train, X_test, y_train, y_test, min_alpha=-10, max_alpha=10, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el logspace de prueba, queremos un valor de alpha mas alto que nos permita sacar mas variables sin empeorar demasiado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_selection(X_train, X_test, y_train, y_test, min_alpha=0, max_alpha=5, steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos iterar multiples veces eliminando las peores variables en cada una. Vamos a eliminar en cada iteracion las peores cinco variables y corroborar los mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ajustar alpha a 0 como minimo para el logspace. Fue uno de los mejores valores probados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_ridge_selection(df, min_alpha=-10, max_alpha=10, steps=100, drop_coefs=5):\n",
    "    X = df.drop(columns=[\"Price\"], axis=1)\n",
    "    y = df[\"Price\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    while len(X.columns) > drop_coefs:\n",
    "        worst_coefs = ridge_selection(X_train, X_test, y_train, y_test, min_alpha, max_alpha, steps, n_worst=drop_coefs)\n",
    "        X = X.drop(columns=worst_coefs, axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "iterate_ridge_selection(toyota, min_alpha=0, max_alpha=4, steps=100, drop_coefs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver se puede quitar variables sin que afecte demasiado al modelo. Por el criterio de Navaja de Ockham queremos quedarnos con el modelo m√°s simple. Vamos a probar iterando desde el modelo de 15 variables y sacando de a una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifteen_df = toyota.drop(columns=['m_exec', 'Metallic_Rim', 'Sport_Model', 'm_vvti', 'm_16v', 'HP', 'Radio', 'Met_Color',\n",
    "                              'Central_Lock', 'm_luna', 'm_terra', 'm_sport', 'Airbag_2', 'Airbag_1', 'ABS', 'Tow_Bar',\n",
    "                              'Automatic', 'm_wagon', 'Mistlamps', 'm_sedan', 'BOVAG_Guarantee', 'Backseat_Divider',\n",
    "                              'm_matic4', 'm_sol', 'Airco', 'm_comfort', 'Power_Steering', 'Mfr_Guarantee', 'cc',\n",
    "                              'Boardcomputer', 'm_hatch_b', 'CD_Player', 'Gears',\n",
    "                              'm_gtsi', 'm_g6'], axis=1)\n",
    "iterate_ridge_selection(fifteen_df, min_alpha=0, max_alpha=4, steps=200, drop_coefs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tan solo en la primera iteracion el modelo ya empeora el RMSE en 30 unidades. Consideramos que lo ideal puede ser quedarse con las 15 features, considerando el aumento de RMSE al eliminar mas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toyota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
